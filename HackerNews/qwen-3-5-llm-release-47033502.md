---
title: "Qwen 3.5"
url: "https://huggingface.co/collections/Qwen/qwen35"
hn_id: 47033502
hn_url: "https://news.ycombinator.com/item?id=47033502"
date: 2026-02-16
tags: [ai, llm, open-source, qwen, alibaba, deep-learning]
source: hackernews
---

# Summary

Alibaba's Qwen team has released Qwen 3.5, the latest iteration of their large language model family. The flagship model is Qwen3.5-397B-A17B, a massive 403 billion parameter image-text-to-text model that uses a Mixture of Experts (MoE) architecture with 17 billion active parameters.

This release continues Qwen's aggressive pace of model iterations, following the successful Qwen 2.5 series. The model collection is hosted on Hugging Face and has already garnered significant community interest with over 155 upvotes and active engagement.

The Qwen 3.5 series represents the ongoing competition in the open-weight LLM space, particularly from Chinese AI labs challenging Western counterparts. The model supports multimodal capabilities (image-text-to-text), positioning it as a versatile foundation model for various AI applications.

## Key Takeaways

- Qwen 3.5 flagship model has 403B total parameters with 17B active (MoE architecture)
- Supports multimodal image-text-to-text generation
- Part of Alibaba's continued push in open-weight LLM development
- Available on Hugging Face for community use and evaluation
- Builds on the successful Qwen 2.5 and Qwen 3 series
