---
title: "Radio host David Greene says Google's NotebookLM tool stole his voice"
url: "https://www.washingtonpost.com/technology/2026/02/15/david-greene-google-ai-podcast/"
hn_id: 47025864
hn_url: "https://news.ycombinator.com/item?id=47025864"
date: 2026-02-16
tags: [ai, machine-learning, voice-cloning, ethics, google, nlp]
source: hackernews
---

# Summary
Radio host David Greene has raised concerns that Google's NotebookLM AI tool has cloned his voice without permission. NotebookLM is Google's AI-powered note-taking and research tool that can generate podcast-style audio summaries of documents.

The controversy highlights growing concerns about AI voice synthesis and the unauthorized use of people's voices in generative AI systems. Greene's claim suggests that his distinctive broadcasting voice may have been incorporated into NotebookLM's training data or voice generation capabilities.

This case raises important ethical and legal questions about consent, intellectual property, and the boundaries of AI training data. It joins a growing list of disputes between content creators and AI companies over the use of their work and likeness in AI systems.

The incident is particularly significant because it involves a well-known media figure whose voice is their professional trademark, bringing mainstream attention to issues that have primarily been discussed in technical and legal circles.

## Key Takeaways
- Google's NotebookLM is accused of unauthorized voice cloning of radio host David Greene
- The case highlights ethical concerns about AI voice synthesis and consent
- Professional voices and likenesses may be at risk from AI training practices
- This could have legal implications for AI companies using voice data
- The controversy brings voice cloning concerns into mainstream media discussion
